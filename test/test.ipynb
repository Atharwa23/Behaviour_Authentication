{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92015ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from '../random_forest_model.pkl'...\n",
      "Loading new data from '../Keystrokes.csv'...\n",
      "Preprocessing data (applying to_numeric)...\n",
      "Making 2 predictions on valid data rows...\n",
      "Saving results...\n",
      "\n",
      "--- Prediction Complete ---\n",
      "Results saved to 'keystroke_predictions.csv'\n",
      "\n",
      "Prediction counts:\n",
      "Prediction\n",
      "Imposter    1\n",
      "Genuine     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "MODEL_FILE = '../random_forest_model.pkl'\n",
    "NEW_DATA_FILE = '../Keystrokes.csv'\n",
    "OUTPUT_FILE = 'keystroke_predictions.csv'\n",
    "\n",
    "FEATURE_NAMES = [\n",
    "    'H.period', 'DD.period.t', 'UD.period.t', 'H.t', 'DD.t.i',\n",
    "    'UD.t.i', 'H.i', 'DD.i.e', 'UD.i.e', 'H.e', 'DD.e.five',\n",
    "    'UD.e.five', 'H.five', 'DD.five.Shift.r', 'UD.five.Shift.r',\n",
    "    'H.Shift.r', 'DD.Shift.r.o', 'UD.Shift.r.o', 'H.o', 'DD.o.a',\n",
    "    'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n', 'H.n', 'DD.n.l', 'UD.n.l',\n",
    "    'H.l', 'DD.l.Return', 'UD.l.Return', 'H.Return'\n",
    "]\n",
    "\n",
    "def predict_new_data():\n",
    "   \n",
    "    if not os.path.exists(MODEL_FILE):\n",
    "        print(f\"Error: Model file '{MODEL_FILE}' not found.\")\n",
    "        print(\"Please place your .pkl file in the same directory as this script.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(NEW_DATA_FILE):\n",
    "        print(f\"Error: New data file '{NEW_DATA_FILE}' not found.\")\n",
    "        print(f\"Please update the 'NEW_DATA_FILE' variable in this script to match your file's name.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading model from '{MODEL_FILE}'...\")\n",
    "    try:\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pickle file: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading new data from '{NEW_DATA_FILE}'...\")\n",
    "    try:\n",
    "        new_data = pd.read_csv(NEW_DATA_FILE, header=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Check if all 31 required feature columns are present\n",
    "    missing_cols = [col for col in FEATURE_NAMES if col not in new_data.columns]\n",
    "\n",
    "    # --- 1. FILE-LEVEL CHECK (from previous version) ---\n",
    "    # If columns are missing, apply default values to all rows and exit\n",
    "    if missing_cols:\n",
    "        print(f\"\\nWarning: The new data file is missing required feature columns:\")\n",
    "        print(missing_cols)\n",
    "        print(\"Defaulting all predictions to 'Imposter' with 0.0 Genuine / 1.0 Imposter probability.\")\n",
    "\n",
    "        output_df = new_data.copy()\n",
    "        output_df['Prediction'] = 'Imposter'\n",
    "        output_df['Probability_Genuine'] = 0.0\n",
    "        output_df['Probability_Imposter'] = 1.0\n",
    "\n",
    "        output_df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "        print(\"\\n--- Prediction Complete (Defaulted) ---\")\n",
    "        print(f\"Results saved to '{OUTPUT_FILE}'\")\n",
    "        print(\"\\nPrediction counts:\")\n",
    "        print(output_df['Prediction'].value_counts(dropna=False))\n",
    "        return  # Stop the function here\n",
    "    # --- END OF FILE-LEVEL CHECK ---\n",
    "\n",
    "    # --- 2. ROW-LEVEL PREPROCESSING (New Logic) ---\n",
    "    # If we are here, all columns were found. Proceed with row-by-row prediction.\n",
    "    \n",
    "    # Keep copy of original data to merge with at the end\n",
    "    original_data_with_index = new_data.copy()\n",
    "    original_data_with_index['original_index'] = new_data.index\n",
    "\n",
    "    print(\"Preprocessing data (applying to_numeric)...\")\n",
    "    # Create a copy for processing to avoid SettingWithCopyWarning\n",
    "    new_data_processed = new_data.copy()\n",
    "    for feature in FEATURE_NAMES:\n",
    "        # errors='coerce' turns any non-numeric data into NaN (Not a Number)\n",
    "        new_data_processed[feature] = pd.to_numeric(new_data_processed[feature], errors='coerce')\n",
    "\n",
    "    # Identify good rows (all 31 features are valid numbers)\n",
    "    # and bad rows (at least one feature is NaN)\n",
    "    good_rows_mask = new_data_processed[FEATURE_NAMES].notna().all(axis=1)\n",
    "    bad_rows_mask = ~good_rows_mask\n",
    "\n",
    "    # Initialize prediction columns\n",
    "    new_data_processed['Prediction'] = ''\n",
    "    new_data_processed['Probability_Genuine'] = 0.0\n",
    "    new_data_processed['Probability_Imposter'] = 0.0\n",
    "\n",
    "    # --- 3. Handle Bad Rows ---\n",
    "    # As requested, default rows with *any* missing data to 'Imposter'\n",
    "    num_bad_rows = bad_rows_mask.sum()\n",
    "    if num_bad_rows > 0:\n",
    "        print(f\"Warning: Found {num_bad_rows} rows with missing/invalid data. Defaulting them to 'Imposter'.\")\n",
    "        new_data_processed.loc[bad_rows_mask, 'Prediction'] = 'Imposter'\n",
    "        new_data_processed.loc[bad_rows_mask, 'Probability_Genuine'] = 0.0\n",
    "        new_data_processed.loc[bad_rows_mask, 'Probability_Imposter'] = 1.0\n",
    "\n",
    "    # --- 4. Handle Good Rows ---\n",
    "    num_good_rows = good_rows_mask.sum()\n",
    "    if num_good_rows > 0:\n",
    "        print(f\"Making {num_good_rows} predictions on valid data rows...\")\n",
    "        X_predict_good = new_data_processed.loc[good_rows_mask, FEATURE_NAMES]\n",
    "\n",
    "        try:\n",
    "            predictions_good = model.predict(X_predict_good)\n",
    "            probabilities_good = model.predict_proba(X_predict_good)\n",
    "\n",
    "            new_data_processed.loc[good_rows_mask, 'Prediction'] = predictions_good\n",
    "            new_data_processed.loc[good_rows_mask, 'Probability_Genuine'] = probabilities_good[:, 0]\n",
    "            new_data_processed.loc[good_rows_mask, 'Probability_Imposter'] = probabilities_good[:, 1]\n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"No valid data rows found to make predictions on.\")\n",
    "    \n",
    "    if num_good_rows == 0 and num_bad_rows == 0:\n",
    "        print(\"Error: No data rows found in the file.\")\n",
    "        return\n",
    "\n",
    "    # --- 5. Save Results ---\n",
    "    print(\"Saving results...\")\n",
    "\n",
    "    # Combine original data with the new prediction columns\n",
    "    # The indices of original_data_with_index and new_data_processed are aligned\n",
    "    output_df = original_data_with_index.drop(columns=['original_index'])\n",
    "    output_df['Prediction'] = new_data_processed['Prediction']\n",
    "    output_df['Probability_Genuine'] = new_data_processed['Probability_Genuine']\n",
    "    output_df['Probability_Imposter'] = new_data_processed['Probability_Imposter']\n",
    "\n",
    "\n",
    "    output_df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "    print(\"\\n--- Prediction Complete ---\")\n",
    "    print(f\"Results saved to '{OUTPUT_FILE}'\")\n",
    "    print(\"\\nPrediction counts:\")\n",
    "    print(output_df['Prediction'].value_counts(dropna=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suppress warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    predict_new_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
